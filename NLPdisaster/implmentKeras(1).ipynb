{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON\\Vscode\\Kaggle\\NLPdisaster\n",
      "['extracted', 'implmentKeras.ipynb', 'nlp-getting-started.zip', 'submission.csv', 'submission_example.csv', 'test_trainer']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "# get the current working directory \n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "# get the relevant file names under the current working directory\n",
    "file_name = os.listdir(path)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extracted', 'implmentKeras.ipynb', 'nlp-getting-started.zip', 'submission.csv', 'submission_example.csv', 'test_trainer']\n"
     ]
    }
   ],
   "source": [
    "# Using . as current directory, .. as parent directory\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing folder deleted.\n",
      "Extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the extracted folder\n",
    "extracted_folder_path = os.path.join(os.getcwd(), \"extracted\")\n",
    "\n",
    "try:\n",
    "    # Attempt to delete the folder and its contents\n",
    "    shutil.rmtree(extracted_folder_path)\n",
    "    print(\"Existing folder deleted.\")\n",
    "except FileNotFoundError:\n",
    "    # The folder does not exist\n",
    "    print(\"Folder does not exist, ready to extract.\")\n",
    "except Exception as e:\n",
    "    # Handle other exceptions, such as permission errors\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "# Proceed with the extraction\n",
    "# Assuming the zip file is the second file in the directory listing, adjust as needed\n",
    "zip_file_path = os.path.join(os.getcwd(), os.listdir(\".\")[1])\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "    print(\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 复现 教程\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "train_pd = pd.read_csv(extracted + \"/train.csv\")\n",
    "print(train_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id keyword location                          text  target\n",
      "15  23     NaN      NaN                What's up man?       0\n",
      "16  24     NaN      NaN                 I love fruits       0\n",
      "17  25     NaN      NaN              Summer is lovely       0\n",
      "18  26     NaN      NaN             My car is so fast       0\n",
      "19  28     NaN      NaN  What a goooooooaaaaaal!!!!!!       0\n"
     ]
    }
   ],
   "source": [
    "# print the columns that target is 0 \n",
    "print(train_pd[train_pd[\"target\"] == 0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the target\n",
    "train_pd[\"target\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (7613, 5), test shape: (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "test_pd = pd.read_csv(extracted + \"/test.csv\")\n",
    "# print the shape \n",
    "print(f\"train shape: {train_pd.shape}, test shape: {test_pd.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add extra column to train and test to calculate the length \n",
    "train_pd[\"len\"] = train_pd['text'].apply(lambda x: len(x))\n",
    "test_pd[\"len\"] = test_pd['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     69\n",
       "1     38\n",
       "2    133\n",
       "3     65\n",
       "Name: len, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd[\"len\"][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pd['len'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of the text in the train: 157\n"
     ]
    }
   ],
   "source": [
    "# the maximum length of the text\n",
    "print(f\"max length of the text in the train: {train_pd['len'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the data \n",
    "X = train_pd['text']\n",
    "y = train_pd['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6090,), X_test shape: (1523,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distilled Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON\\ENV\\labsession\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "# add drop out to the model\n",
    "drop_out = 0.2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer \n",
    "X_train_tokenized = tokenizer(X_train.to_list(), padding=True, truncation=True, return_tensors=\"pt\",max_length = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized = tokenizer(X_test.to_list(), padding=True, truncation=True, return_tensors=\"pt\",max_length = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "with torch.no_grad():\n",
    "    X_train_encoded = model(**X_train_tokenized.to(\"cuda\"))\n",
    "\n",
    "# this three dim stands for batch size, sequence length, hidden size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X_test_encoded = model(**X_test_tokenized.to(\"cuda\"))\n",
    "\n",
    "# print(X_test_encoded.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6090]) torch.Size([1523])\n"
     ]
    }
   ],
   "source": [
    "# process y \n",
    "# Instead of .to(\"cuda\"), keep them on the CPU\n",
    "y_train = torch.tensor(y_train.tolist())  # Already on CPU by default\n",
    "y_test = torch.tensor(y_test.tolist())    # Already on CPU by default\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert/distilbert-base-uncased\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.38.2\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check our model \n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {k: v.cpu() for k, v in encodings.items()}  # Ensure encodings are on CPU\n",
    "        self.labels = labels.cpu()  # Ensure labels are on CPU\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}  # Clone to ensure no grad\n",
    "        item['labels'] = self.labels[idx].clone().detach()  # Clone to ensure no grad\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "# Create instances of CustomDataset\n",
    "train_dataset = CustomDataset(X_train_tokenized, y_train)\n",
    "test_dataset = CustomDataset(X_test_tokenized, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing checkpoint folder: ./test_trainer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Specify the path to the checkpoint folder\n",
    "checkpoint_folder = \"./test_trainer\"\n",
    "\n",
    "try:\n",
    "    # Attempt to delete the checkpoint folder and its contents\n",
    "    shutil.rmtree(checkpoint_folder)\n",
    "    print(f\"Deleted existing checkpoint folder: {checkpoint_folder}\")\n",
    "except FileNotFoundError:\n",
    "    # The checkpoint folder does not exist\n",
    "    print(\"No existing checkpoint folder to delete.\")\n",
    "except Exception as e:\n",
    "    # An unexpected error occurred\n",
    "    print(f\"Error occurred while trying to delete checkpoint folder: {e}\")\n",
    "\n",
    "# Proceed with the rest of your script here, such as setting up TrainingArguments and initializing the Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON\\ENV\\labsession\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "  3%|▎         | 102/3810 [00:07<02:55, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0542, 'grad_norm': 0.2939712703227997, 'learning_rate': 1e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 204/3810 [00:11<02:45, 21.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1165, 'grad_norm': 0.2624434232711792, 'learning_rate': 2e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 303/3810 [00:16<02:43, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1001, 'grad_norm': 0.05035383254289627, 'learning_rate': 3e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 405/3810 [00:21<02:38, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0834, 'grad_norm': 0.0066613624803721905, 'learning_rate': 4e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 500/3810 [00:25<02:31, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1069, 'grad_norm': 0.01729053445160389, 'learning_rate': 5e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 603/3810 [00:30<02:31, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1128, 'grad_norm': 0.01970563270151615, 'learning_rate': 4.848942598187312e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 702/3810 [00:35<02:25, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1932, 'grad_norm': 8.049954414367676, 'learning_rate': 4.6978851963746225e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 804/3810 [00:40<02:19, 21.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1259, 'grad_norm': 161.18673706054688, 'learning_rate': 4.546827794561934e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 903/3810 [00:44<02:16, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0656, 'grad_norm': 0.017494676634669304, 'learning_rate': 4.395770392749245e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1000/3810 [00:49<02:08, 21.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1454, 'grad_norm': 0.1460566371679306, 'learning_rate': 4.244712990936556e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1104/3810 [00:54<02:04, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1319, 'grad_norm': 0.012167723849415779, 'learning_rate': 4.093655589123867e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1203/3810 [00:59<01:59, 21.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1348, 'grad_norm': 5.173732757568359, 'learning_rate': 3.9425981873111784e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1305/3810 [01:03<01:52, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1329, 'grad_norm': 0.03252275288105011, 'learning_rate': 3.79154078549849e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1404/3810 [01:08<01:49, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0888, 'grad_norm': 0.06693843007087708, 'learning_rate': 3.640483383685801e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1500/3810 [01:12<01:44, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1581, 'grad_norm': 0.2668377459049225, 'learning_rate': 3.489425981873112e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1605/3810 [01:17<01:40, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1029, 'grad_norm': 0.07166309654712677, 'learning_rate': 3.338368580060423e-05, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 1704/3810 [01:22<01:35, 21.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0501, 'grad_norm': 0.050900209695100784, 'learning_rate': 3.187311178247734e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1803/3810 [01:26<01:33, 21.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0977, 'grad_norm': 0.9935785531997681, 'learning_rate': 3.0362537764350457e-05, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1902/3810 [01:31<01:27, 21.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0711, 'grad_norm': 0.007462955545634031, 'learning_rate': 2.8851963746223565e-05, 'epoch': 2.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2000/3810 [01:35<01:22, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0812, 'grad_norm': 7.92999267578125, 'learning_rate': 2.734138972809668e-05, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2103/3810 [01:40<01:17, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0866, 'grad_norm': 10.534989356994629, 'learning_rate': 2.583081570996979e-05, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2202/3810 [01:45<01:12, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0703, 'grad_norm': 0.03986269608139992, 'learning_rate': 2.43202416918429e-05, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2304/3810 [01:50<01:07, 22.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0701, 'grad_norm': 0.010195632465183735, 'learning_rate': 2.2809667673716012e-05, 'epoch': 3.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2403/3810 [01:54<01:03, 22.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0315, 'grad_norm': 0.01080079935491085, 'learning_rate': 2.1299093655589124e-05, 'epoch': 3.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 2500/3810 [01:58<00:58, 22.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0849, 'grad_norm': 0.008697696961462498, 'learning_rate': 1.9788519637462235e-05, 'epoch': 3.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2604/3810 [02:04<00:55, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0764, 'grad_norm': 33.17705535888672, 'learning_rate': 1.827794561933535e-05, 'epoch': 3.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 2703/3810 [02:08<00:50, 21.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0526, 'grad_norm': 0.00791336689144373, 'learning_rate': 1.676737160120846e-05, 'epoch': 3.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 2802/3810 [02:13<00:46, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0524, 'grad_norm': 0.19626398384571075, 'learning_rate': 1.5256797583081573e-05, 'epoch': 3.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 2904/3810 [02:17<00:41, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0415, 'grad_norm': 0.4594835638999939, 'learning_rate': 1.3746223564954682e-05, 'epoch': 3.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 3000/3810 [02:22<00:37, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0423, 'grad_norm': 1.807619333267212, 'learning_rate': 1.2235649546827795e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 3102/3810 [02:27<00:33, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0553, 'grad_norm': 0.004785178694874048, 'learning_rate': 1.0725075528700906e-05, 'epoch': 4.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3204/3810 [02:32<00:28, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0384, 'grad_norm': 0.0042624385096132755, 'learning_rate': 9.214501510574018e-06, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 3303/3810 [02:36<00:23, 21.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.033, 'grad_norm': 1.7657631635665894, 'learning_rate': 7.70392749244713e-06, 'epoch': 4.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 3405/3810 [02:41<00:18, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0514, 'grad_norm': 0.0046674711629748344, 'learning_rate': 6.193353474320241e-06, 'epoch': 4.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 3500/3810 [02:45<00:14, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0303, 'grad_norm': 0.003218071535229683, 'learning_rate': 4.682779456193353e-06, 'epoch': 4.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 3603/3810 [02:50<00:09, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0267, 'grad_norm': 0.003060894086956978, 'learning_rate': 3.1722054380664653e-06, 'epoch': 4.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 3705/3810 [02:55<00:04, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0398, 'grad_norm': 119.60929107666016, 'learning_rate': 1.661631419939577e-06, 'epoch': 4.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3804/3810 [03:00<00:00, 22.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0423, 'grad_norm': 1.1280299425125122, 'learning_rate': 1.5105740181268883e-07, 'epoch': 4.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3810/3810 [03:00<00:00, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 180.3328, 'train_samples_per_second': 168.854, 'train_steps_per_second': 21.128, 'train_loss': 0.08087695457647479, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3810, training_loss=0.08087695457647479, metrics={'train_runtime': 180.3328, 'train_samples_per_second': 168.854, 'train_steps_per_second': 21.128, 'train_loss': 0.08087695457647479, 'epoch': 5.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## batch \n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(output_dir = \"test_trainer\",\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  per_device_eval_batch_size=8,\n",
    "                                  num_train_epochs=5,\n",
    "                                  warmup_steps=500,\n",
    "                                  weight_decay=0.01,\n",
    "                                  logging_dir=\"./logs\",\n",
    "                                  logging_steps=100,)\n",
    "\n",
    "\n",
    "trainer= Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=test_dataset)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "training_args = TrainingArguments(output_dir = \"test_trainer\",\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  per_device_eval_batch_size=8,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_dir=\"./logs\",\n",
    "                                  logging_steps=10,)\n",
    "```\n",
    "\n",
    "这个loggingfrequency会返回很多epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON\\ENV\\labsession\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "  0%|          | 0/2286 [06:09<?, ?it/s]\n",
      "  0%|          | 0/2286 [04:48<?, ?it/s]\n",
      " 22%|██▏       | 500/2286 [00:22<01:19, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4635, 'grad_norm': 4.250698089599609, 'learning_rate': 3.906386701662293e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 1000/2286 [00:45<00:57, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3799, 'grad_norm': 0.9546465277671814, 'learning_rate': 2.8127734033245845e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1500/2286 [01:08<00:34, 23.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3355, 'grad_norm': 10.752007484436035, 'learning_rate': 1.7191601049868766e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2000/2286 [01:31<00:12, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2128, 'grad_norm': 12.658132553100586, 'learning_rate': 6.255468066491689e-06, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2286/2286 [01:44<00:00, 21.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 104.4352, 'train_samples_per_second': 174.941, 'train_steps_per_second': 21.889, 'train_loss': 0.33185428208879286, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2286, training_loss=0.33185428208879286, metrics={'train_runtime': 104.4352, 'train_samples_per_second': 174.941, 'train_steps_per_second': 21.889, 'train_loss': 0.33185428208879286, 'epoch': 3.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import Trainer, TrainingArguments\n",
    "# training_args = TrainingArguments(\"test_trainer\")\n",
    "\n",
    "\n",
    "# trainer= Trainer(model=model,\n",
    "#                   args=training_args,\n",
    "#                   train_dataset=train_dataset,\n",
    "#                   eval_dataset=test_dataset)\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "\n",
    "\n",
    "# test the model\n",
    "# load the test data\n",
    "X_val = test_pd['text']\n",
    "\n",
    "X_val_tokenized = tokenizer(X_val.to_list(), padding=True, truncation=True, return_tensors=\"pt\",max_length = 200)\n",
    "\n",
    "\n",
    "# create the dataset\n",
    "\n",
    "\n",
    "# make the prediction\n",
    "with torch.no_grad():\n",
    "    X_val_encoded = model(**X_val_tokenized.to(\"cuda\"))\n",
    "\n",
    "# write the prediction to a csv file\n",
    "# get the prediction\n",
    "y_val = torch.argmax(X_val_encoded.logits, dim=1).cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8994790070487282\n",
      "F1 Score: 0.8681672025723473\n"
     ]
    }
   ],
   "source": [
    "# create the submission file\n",
    "from sklearn.metrics import f1_score\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_pd['id']\n",
    "submission['target'] = y_val\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# \n",
    "with open(\"submission_example.csv\", \"r\") as f:\n",
    "    # check the accuracy\n",
    "    submission_example = pd.read_csv(f)\n",
    "\n",
    "    # check the accuracy\n",
    "accuracy = (submission_example['target'] == submission['target']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# check the f1 score\n",
    "f1 = f1_score(submission_example['target'], submission['target'])\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert uncased normal model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON\\ENV\\labsession\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\PYTHON\\cacheTransformers\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## let's try another bert \n",
    "tokenizer_new = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model_new = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize_x \n",
    "X_train_tokenized_new = tokenizer_new(X_train.to_list(), padding=True, truncation=True, return_tensors=\"pt\",max_length = 200)\n",
    "X_test_tokenized_new = tokenizer_new(X_test.to_list(), padding=True, truncation=True, return_tensors=\"pt\",max_length = 200)\n",
    "y_train = torch.tensor(y_train.tolist())  # Already on CPU by default\n",
    "y_test = torch.tensor(y_test.tolist())    # Already on CPU by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON\\ENV\\labsession\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      " 13%|█▎        | 500/3810 [00:58<06:28,  8.53it/s]Checkpoint destination directory test_trainer_newbert\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      " 26%|██▌       | 1000/3810 [01:56<05:27,  8.58it/s]Checkpoint destination directory test_trainer_newbert\\checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      " 39%|███▉      | 1500/3810 [02:55<04:19,  8.92it/s]Checkpoint destination directory test_trainer_newbert\\checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      " 52%|█████▏    | 2000/3810 [03:52<03:28,  8.69it/s]Checkpoint destination directory test_trainer_newbert\\checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      " 66%|██████▌   | 2500/3810 [04:50<02:31,  8.65it/s]Checkpoint destination directory test_trainer_newbert\\checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      " 79%|███████▊  | 3000/3810 [05:49<01:34,  8.53it/s]Checkpoint destination directory test_trainer_newbert\\checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      " 92%|█████████▏| 3500/3810 [06:49<00:36,  8.44it/s]Checkpoint destination directory test_trainer_newbert\\checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "100%|██████████| 3810/3810 [07:26<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 446.6418, 'train_samples_per_second': 136.351, 'train_steps_per_second': 8.53, 'train_loss': 0.06501716753942134, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3810, training_loss=0.06501716753942134, metrics={'train_runtime': 446.6418, 'train_samples_per_second': 136.351, 'train_steps_per_second': 8.53, 'train_loss': 0.06501716753942134, 'epoch': 10.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dataset\n",
    "train_dataset_new = CustomDataset(X_train_tokenized_new, y_train)\n",
    "test_dataset_new = CustomDataset(X_test_tokenized_new, y_test)\n",
    "\n",
    "# Specify the path to the checkpoint folder\n",
    "checkpoint_folder = \"./test_trainer_newbert\"\n",
    "# ## batch \n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(output_dir = \"test_trainer_newbert\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  per_device_eval_batch_size=16,\n",
    "                                  num_train_epochs=10,\n",
    "                                  warmup_steps=500,\n",
    "                                  weight_decay=0.01,\n",
    "                                  logging_dir=\"./logs_new\",\n",
    "                                  logging_steps=5000,)\n",
    "\n",
    "\n",
    "trainer= Trainer(model=model_new,\n",
    "                  args=training_args,\n",
    "                  train_dataset=train_dataset_new,\n",
    "                  eval_dataset=test_dataset_new)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "# load the test data\n",
    "X_val_new = test_pd['text']# evaluate the model\n",
    "\n",
    "\n",
    "\n",
    "# test the model\n",
    "# load the test data\n",
    "X_val_new = test_pd['text']\n",
    "\n",
    "\n",
    "X_val_tokenized_new = tokenizer_new(X_val_new.to_list(), padding=True, truncation=True, return_tensors=\"pt\",max_length = 200)\n",
    "\n",
    "\n",
    "# create the dataset\n",
    "\n",
    "\n",
    "# make the prediction\n",
    "with torch.no_grad():\n",
    "    X_val_encoded_new = model_new(**X_val_tokenized_new.to(\"cuda\"))\n",
    "\n",
    "# write the prediction to a csv file\n",
    "# get the prediction\n",
    "y_val_new = torch.argmax(X_val_encoded_new.logits, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8970272755133313\n",
      "F1 Score: 0.8615004122011541\n"
     ]
    }
   ],
   "source": [
    "# create the submission file\n",
    "from sklearn.metrics import f1_score\n",
    "submission_bert = pd.DataFrame()\n",
    "submission_bert['id'] = test_pd['id']\n",
    "submission_bert['target'] = y_val_new\n",
    "submission_bert.to_csv(\"submission_bert.csv\", index=False)\n",
    "\n",
    "# \n",
    "with open(\"submission_example.csv\", \"r\") as f:\n",
    "    # check the accuracy\n",
    "    submission_example = pd.read_csv(f)\n",
    "\n",
    "    # check the accuracy\n",
    "accuracy = (submission_example['target'] == submission_bert['target']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# check the f1 score\n",
    "f1 = f1_score(submission_example['target'], submission_bert['target'])\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomDistilBertModel(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(CustomDistilBertModel, self).__init__()\n",
    "        config = DistilBertConfig.from_pretrained('distilbert-base-uncased', \n",
    "                                                  dropout=0.3, \n",
    "                                                  attention_dropout=0.2,\n",
    "                                                  num_labels=num_labels) # Ensure num_labels is set in the config\n",
    "        self.distilbert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "        self.dropout = nn.Dropout(0.5)  # Additional dropout if needed\n",
    "        # No need to add another classifier on top, DistilBertForSequenceClassification already includes one\n",
    "        # If you want to replace the classifier, ensure it matches the output feature size of DistilBERT (768)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # DistilBertForSequenceClassification returns a sequence of hidden states as the first element of the output\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # For DistilBertForSequenceClassification, the logits are what you're interested in\n",
    "        # which are located in `outputs.logits`\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Apply additional dropout to the logits if desired\n",
    "        logits = self.dropout(logits)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Usage\n",
    "model_dp = CustomDistilBertModel(num_labels=2).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomDistilBertModel(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        config = DistilBertConfig.from_pretrained('distilbert-base-uncased', \n",
    "                                                  dropout=0.3, \n",
    "                                                  attention_dropout=0.2,\n",
    "                                                  num_labels=num_labels)\n",
    "        self.distilbert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        \n",
    "        return outputs  # Directly return the output from DistilBertForSequenceClassification\n",
    "\n",
    "# Usage\n",
    "model_dp = CustomDistilBertModel(num_labels=2).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3810 [02:58<?, ?it/s]\n",
      "                                                   \n",
      "100%|██████████| 3810/3810 [03:59<00:00, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 239.93, 'train_samples_per_second': 253.824, 'train_steps_per_second': 15.88, 'train_loss': 0.21832047910515093, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3810, training_loss=0.21832047910515093, metrics={'train_runtime': 239.93, 'train_samples_per_second': 253.824, 'train_steps_per_second': 15.88, 'train_loss': 0.21832047910515093, 'epoch': 10.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process the data \n",
    "X_train_tokenized = model\n",
    "# start the training\n",
    "# Specify the path to the checkpoint folder\n",
    "checkpoint_folder = \"./test_trainer_dp\"\n",
    "\n",
    "# ## batch \n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(output_dir = \"test_trainer_dp\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  per_device_eval_batch_size=16,\n",
    "                                  num_train_epochs=10,\n",
    "                                  warmup_steps=500,\n",
    "                                  weight_decay=0.01,\n",
    "                                  logging_dir=\"./logs_new\",\n",
    "                                  logging_steps=5000,)\n",
    "\n",
    "\n",
    "\n",
    "trainer= Trainer(model=model_dp,\n",
    "                  args=training_args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=test_dataset)\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "# test the model\n",
    "# load the test data\n",
    "X_val_dp= test_pd['text']# evaluate the model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_val_tokenized_dp = tokenizer(X_val_dp.to_list(), padding=True, truncation=True, return_tensors=\"pt\",max_length = 200)\n",
    "\n",
    "\n",
    "# create the dataset\n",
    "\n",
    "\n",
    "# make the prediction\n",
    "with torch.no_grad():\n",
    "    X_val_encoded_dp = model_dp(**X_val_tokenized_dp.to(\"cuda\"))\n",
    "\n",
    "# write the prediction to a csv file\n",
    "# get the prediction\n",
    "y_val_dp = torch.argmax(X_val_encoded_dp.logits, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8945755439779344\n",
      "F1 Score: 0.8639240506329114\n"
     ]
    }
   ],
   "source": [
    "# create the submission file\n",
    "from sklearn.metrics import f1_score\n",
    "submission_bert_dp = pd.DataFrame()\n",
    "submission_bert_dp['id'] = test_pd['id']\n",
    "submission_bert_dp['target'] = y_val_dp\n",
    "submission_bert_dp.to_csv(\"submission_bert_dp.csv\", index=False)\n",
    "\n",
    "# \n",
    "with open(\"submission_example.csv\", \"r\") as f:\n",
    "    # check the accuracy\n",
    "    submission_example = pd.read_csv(f)\n",
    "\n",
    "    # check the accuracy\n",
    "accuracy = (submission_example['target'] == submission_bert_dp['target']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# check the f1 score\n",
    "f1 = f1_score(submission_example['target'], submission_bert_dp['target'])\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labsession",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
